{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "endless-forge",
   "metadata": {},
   "source": [
    "# Code demo 19/05/2021 Flagship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-warner",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-thought",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-hygiene",
   "metadata": {},
   "source": [
    "- petit discours d'introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nominated-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import csv\n",
    "import reprlib\n",
    "import numpy\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-server",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-nigeria",
   "metadata": {},
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-actor",
   "metadata": {},
   "source": [
    "### Création de la Base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ahead-market",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problème lors de la connection à la base de donnée\n",
      "ERREUR:  la base de données « collection4 » existe déjà\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Connexion dans un premier temps à postgres\n",
    "pour initialiser notre database collection\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# initialisation des variables  de connection\n",
    "utilisateur = \"postgres\"\n",
    "\n",
    "mot_passe = os.environ.get('pg_psw')\n",
    "\n",
    "base_de_donnees = \"postgres\"\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    \n",
    "    # création de l'objet conn\n",
    "\n",
    "    conn = psycopg2.connect(dbname= base_de_donnees, user=utilisateur, password=mot_passe, host=\"localhost\", port= 5432)\n",
    "\n",
    "    conn.set_session(autocommit=True)   # on force\n",
    "\n",
    "    # initialisation du cursor\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # cursor.execute permet d'exécuter une commande 'sql'\n",
    "\n",
    "    cursor.execute(\"CREATE DATABASE collection4\")\n",
    "\n",
    "    print(\"La DataBase à été créée avec succès !\")\n",
    "\n",
    "        \n",
    "except psycopg2.Error as e:\n",
    "    \n",
    "    print(\"Problème lors de la connection à la base de donnée\")\n",
    "\n",
    "    print(e)\n",
    "\n",
    "   \n",
    "    \n",
    "finally:\n",
    "        \n",
    "    # ferme le curseur et devient inutilisable\n",
    "\n",
    "    cursor.close\n",
    "\n",
    "    # ferme la connexion à database\n",
    "\n",
    "    conn.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-greek",
   "metadata": {},
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dense-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cellule pour nos fonctions de connection\n",
    "\n",
    "# Fonction qui va nous permettre de créer une Base de données.\n",
    "def ouvrir_connection(base_de_donnee, utilisateur, mot_passe, host='localhost', port=5432):\n",
    "    \n",
    "    try:\n",
    "        # création de l'objet conn\n",
    "        conn = psycopg2.connect(dbname= base_de_donnee, user=utilisateur, password = mot_passe, host=\"localhost\", port= 5432)\n",
    "\n",
    "        # on force la sauvegarde\n",
    "        conn.set_session(autocommit=True)   \n",
    "        \n",
    "        # initialisation du cursor\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # exécution de la requête sql de création de la base de donnée\n",
    "        #cursor.execute(\"CREATE DATABASE IF NOT EXISTS movie\")\n",
    "\n",
    "    # gestion des erreurs    \n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Problème lors de la connection à la base de donnée\")\n",
    "        print(e)\n",
    "        return None\n",
    "    # dans tous les cas on va clôturer la session\n",
    "    finally:\n",
    "        cursor.close\n",
    "        conn.close\n",
    "    return conn\n",
    "   \n",
    "    # fonction pour supprimer une table\n",
    "def supprimer_table(conn, sql_suppression_table):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_suppression_table)\n",
    "        conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Erreur lors de la suppression de la table\")\n",
    "        print(e)\n",
    "        return\n",
    "    cursor.close()\n",
    "    print(\"La table a été supprimée avec succès\")\n",
    "\n",
    "# fonction pour créer une table    \n",
    "def creer_table(conn, sql_creer_table):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_creer_table)\n",
    "        conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Erreur lors de la création de la table\")\n",
    "        print(e)\n",
    "        return\n",
    "    cursor.close()\n",
    "    print(\"La table a été crée avec succès\")\n",
    "\n",
    "# fonction de lecture de la table    \n",
    "def lire_table(conn, sql_lire_donnee):\n",
    "    try:\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(sql_lire_donnee)\n",
    "        conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"Erreur lors de la lecture des données\")\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    print(\"Les données ont été lues avec succès\")\n",
    "    \n",
    "    data = []\n",
    "    for row in cursor:\n",
    "        data.append(row)\n",
    "\n",
    "    cursor.close()\n",
    "    \n",
    "    return data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "waiting-bidder",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cellule qui content différentes requêtes sql\n",
    "\"\"\"\n",
    "\n",
    "# requète création table d'origine\n",
    "sql_creer_table1 = \"\"\"CREATE TABLE IF NOT EXISTS Origine(\n",
    "   code_Origine SERIAL,\n",
    "   nom_origine VARCHAR(100),\n",
    "   PRIMARY KEY(Code_Origine)\n",
    ");\n",
    "\"\"\"\n",
    "# requète création table producteur\n",
    "sql_creer_table2 = \"\"\"CREATE TABLE IF NOT EXISTS Producteur(\n",
    "   code_producteur SERIAL,\n",
    "   nom_producteur VARCHAR(100),\n",
    "   code_Origine INT,\n",
    "   PRIMARY KEY(Code_producteur),\n",
    "   FOREIGN KEY(Code_Origine) REFERENCES Origine(Code_Origine)\n",
    ");\n",
    "\"\"\"\n",
    "# requète création table produit\n",
    "sql_creer_table3 = \"\"\"CREATE TABLE IF NOT EXISTS Produit(\n",
    "   code_produit SERIAL,\n",
    "   nom_produit VARCHAR(250),\n",
    "   volume INT,\n",
    "   degre DECIMAL(15,2),\n",
    "   code_producteur INT,\n",
    "   PRIMARY KEY(Code_produit),\n",
    "   FOREIGN KEY(Code_producteur) REFERENCES Producteur(Code_producteur)\n",
    ");\n",
    "\"\"\"\n",
    "sql_creer_table4 = \"\"\"CREATE TABLE IF NOT EXISTS Utilisateur(\n",
    "   code_utilisateur SERIAL,\n",
    "   nom VARCHAR(100),\n",
    "   surnom VARCHAR(100),\n",
    "   email VARCHAR(150),\n",
    "   PRIMARY KEY(code_utilisateur)\n",
    ");\n",
    "\"\"\"\n",
    "sql_creer_table5 = \"\"\"CREATE TABLE IF NOT EXISTS Collection(\n",
    "   Code_collection SERIAL,\n",
    "   nom VARCHAR(250),\n",
    "   description VARCHAR(500),\n",
    "   code_utilisateur INT,\n",
    "   PRIMARY KEY(Code_collection),\n",
    "   UNIQUE(code_utilisateur),\n",
    "   FOREIGN KEY(code_utilisateur) REFERENCES Utilisateur(code_utilisateur)\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql_creer_table6 = \"\"\"CREATE TABLE IF NOT EXISTS Compose(\n",
    "   Code_produit INT,\n",
    "   Code_collection INT,\n",
    "   description VARCHAR(250),\n",
    "   PRIMARY KEY(Code_produit, Code_collection),\n",
    "   FOREIGN KEY(Code_produit) REFERENCES Produit(Code_produit),\n",
    "   FOREIGN KEY(Code_collection) REFERENCES Collection(Code_collection)\n",
    ");\n",
    "\"\"\"\n",
    "sql_creer_table7 = \"\"\"CREATE TABLE role(\n",
    "   code_role INT,\n",
    "   nom VARCHAR(50),\n",
    "   PRIMARY KEY(code_role)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "sql_creer_table8 = \"\"\"CREATE TABLE Droit(\n",
    "   code_droit INT,\n",
    "   permission VARCHAR(50),\n",
    "   PRIMARY KEY(code_droit)\n",
    ");\n",
    "\"\"\"\n",
    "# requète lecture des données\n",
    "sql_lire_donnee = \"\"\"\n",
    "    SELECT *\n",
    "    FROM Produit\n",
    "    LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comprehensive-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables pour me connecter à ma bdd postgres\n",
    "\n",
    "base_de_donnee = \"collection4\"\n",
    "\n",
    "utilisateur = \"postgres\"\n",
    "\n",
    "mot_passe = os.environ.get('pg_psw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incorporated-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation de ma connection\n",
    "conn = ouvrir_connection(base_de_donnee, utilisateur, mot_passe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création table origine\n",
    "creer_table(conn, sql_creer_table1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création table producteur\n",
    "creer_table(conn, sql_creer_table2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création table produit\n",
    "creer_table(conn, sql_creer_table3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "limited-income",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La table a été crée avec succès\n"
     ]
    }
   ],
   "source": [
    "# création table produit\n",
    "creer_table(conn, sql_creer_table4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "tired-artist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La table a été crée avec succès\n"
     ]
    }
   ],
   "source": [
    "# création table produit\n",
    "creer_table(conn, sql_creer_table5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création table produit\n",
    "creer_table(conn, sql_creer_table6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-camel",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-shade",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-luxembourg",
   "metadata": {},
   "source": [
    "### Nettoyage des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-geology",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-lawsuit",
   "metadata": {},
   "source": [
    "- nettoyage fichier excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_file = 'INVENTAIRE_A.xlsx'\n",
    "inventaire = pd.read_excel(excel_file, skiprows=2)\n",
    "inventaire.drop(99,0,inplace=True)\n",
    "inventaire.drop(0,0,inplace=True)\n",
    "del inventaire['Unnamed: 5']\n",
    "inventaire.columns = ['NOM', 'VOLUME', 'DEGRE', 'NOMBRE', 'PRIX', 'MARQUE']\n",
    "index_with_nan = inventaire.index[inventaire.isnull().any(axis=1)]\n",
    "inventaire.drop(index_with_nan,0, inplace=True)\n",
    "inventaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventaire.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventaire.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventaire.to_excel(r'INVENTAIRE_B.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-liberia",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-requirement",
   "metadata": {},
   "source": [
    "- nettoyage fichier rhum_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'rum_data_brut.csv'\n",
    "liste_rhum = pd.read_csv(csv_file)\n",
    "\n",
    "liste_rhum.head(275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-petroleum",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unknown = liste_rhum['company'] == 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = liste_rhum[list_unknown]\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in liste_rhum.itertuples():\n",
    "    print(x.company) # Imprime la valeur courante de la colonne A de df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on change les valeurs inconnus par le nom de la bouteille\n",
    "liste_rhum.loc[liste_rhum['company'] == 'Unknown', 'company'] = liste_rhum['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rhum.to_csv('rum_data_new2.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-friendly",
   "metadata": {},
   "source": [
    "- remplacement des caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'rum_data_new2.csv'\n",
    "liste_rhum = pd.read_csv(csv_file)\n",
    "\n",
    "liste_rhum.head(275)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-hearing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df.replace([old_value], new_value)\n",
    "# création liste caractère spéciaux et leurs valeurs de remplacement\n",
    "dico = {}\n",
    "liste_car = ['Ã¡', 'Ã»', 'Ã¢', 'Ã©', 'â€™', 'Â°', 'Ã¨', 'Ã³', 'Ã±', '\\'', 'Ã£']\n",
    "liste_remp = ['a', 'u', 'a', 'e', '', '°', 'e', 'o', 'n', '', 'a']\n",
    "# création du dictionnaire avec une compréhension de dictionnaire\n",
    "dico = {k: v for k, v in zip(liste_car, liste_remp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut que regex=True \n",
    "liste_rhum.replace({'name': dico}, regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-timber",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rhum.replace({'company': dico}, regex=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_rhum.to_csv('rum_data_new3.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-hybrid",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-memorabilia",
   "metadata": {},
   "source": [
    "- nettoyage fichier json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "origines = []\n",
    "degres = []\n",
    "volumes = []\n",
    "noms = []\n",
    "producteurs = []\n",
    "marques = []\n",
    "liste_json = []\n",
    "\n",
    "with open('test.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for rum in data:\n",
    "    for k, v in rum.items():\n",
    "        v = v.replace(' cl', 'cl')\n",
    "        liste_json.append(v)\n",
    "        \n",
    "for element in liste_json:\n",
    "    \n",
    "    # Origines\n",
    "    pays = element.split()[-1]\n",
    "    origines.append(pays)\n",
    "    if pays:\n",
    "        element = element.replace(pays, \"\")\n",
    "        \n",
    "    # Producteurs  \n",
    "    marque_pattern = re.compile(r\"[a-zA-Zèé]+[&? [a-zA-Zèé0-9']+ Rhum|[a-zA-Zèé']+[ ]? Rhum|[a-zA-Zèé']+ [Liqueur|Punch|Coffret]+\")\n",
    "    marque = marque_pattern.findall(element)\n",
    "#     marque = marque.replace(\"Rhum\", \"\")\n",
    "    if marque:\n",
    "        marques.append(marque[0])\n",
    "    else:\n",
    "        marques.append(\"XXXXXXXX\")\n",
    "\n",
    "    # Degres    \n",
    "    degre_pattern = re.compile(r'\\d\\d°|\\d\\d,\\d\\d?°|\\d\\d\\.\\d\\d?°')\n",
    "    degre = degre_pattern.findall(element)\n",
    "    if degre:\n",
    "        element = element.replace(degre[0], \"\")\n",
    "        degres.append(degre[0])\n",
    "    else:\n",
    "        degres.append(\"\")\n",
    "        \n",
    "    # Volumes\n",
    "    volume_pattern = re.compile(r'\\d?\\dcl|\\dL')\n",
    "    volume = volume_pattern.findall(element)\n",
    "    if volume:\n",
    "        element = element.replace(volume[0], \"\")\n",
    "        volumes.append(volume[0])\n",
    "    else:\n",
    "        volumes.append('')\n",
    "        \n",
    "    # Noms rhums    \n",
    "    noms.append(element) \n",
    "\n",
    "# nettoyage Producteurs   \n",
    "for producteur in marques:\n",
    "    producteur = re.sub('Rhum|Liqueur|Punch|Coffret', '', producteur)\n",
    "    producteurs.append(producteur)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "df1['noms'] = noms\n",
    "df1['producteurs'] = producteurs\n",
    "df1['origines'] = origines\n",
    "df1['volumes'] = volumes\n",
    "df1['degres'] = degres\n",
    "df1.head(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('test_json_new.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('test_json_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['producteurs'] = df1['producteurs'].replace('XXXXXXXX', 'Bumbu') \n",
    "df1['producteurs'] = df1['producteurs'].replace('JM', 'Rhum JM') \n",
    "df1['producteurs'] = df1['producteurs'].replace('James C', 'Saint James') \n",
    "df1['producteurs'] = df1['producteurs'].replace('Depaz Doré', 'Depaz') \n",
    "df1['producteurs'] = df1['producteurs'].replace('pour rhu', 'Quai Sud') \n",
    "df1['producteurs'] = df1['producteurs'].replace(['Maison L', 'Maison La Mauny'], 'La Mauny') \n",
    "df1['origines'] = df1['origines'].replace('70cl', 'Guadeloupe') \n",
    "df1.loc[df1['producteurs'] == 'Maison La Mauny', 'producteurs'] = 'La Mauny'\n",
    "df1.loc[df1['producteurs'] == 'Depaz Doré', 'producteurs'] = 'Depaz'\n",
    "df1.head(241)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('test_json_work.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('test_json_work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-render",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico = {}\n",
    "liste_car = ['XXXXXXXX', 'JM', 'Depaz Doré', 'Maison La Mauny', 'Maison L', '\\'', \n",
    "             'de Cori', 'Longueteau  Vieux Cuvée Confrérie du','Bielle  Vieux Millésime 2009 Cuvée Confrérie du', \n",
    "             'Discovery', 'Ambré Brun', 'Crème de', 'Favorite  Vieux coeur de', 'VSOP', '4 tubes de', 'Blanc de', \n",
    "             'Latitudes', 'pour rhu', 'James C', 'Depaz Doré', 'Blanc Ice', 'Favorite  Vieux Coeur de',\n",
    "             'Favorite', 'Bally','é','è']\n",
    "liste_remp = ['Bumbu', 'Rhum JM', 'Depaz', 'La Mauny', 'La Mauny', '', \n",
    "              'Saveur de Coriandre', 'Confrérie du Rhum','Confrérie du Rhum', 'Rhum', '', \n",
    "              '', 'Favorite', '', '', '', 'Grand Fond Gallion', 'Quai Sud', 'Saint James', 'Depaz', '',\n",
    "              'La Favorite', 'La Favorite', 'J. Bally','e', 'e']\n",
    "# création du dictionnaire avec une compréhension de dictionnaire\n",
    "dico = {k: v for k, v in zip(liste_car, liste_remp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico2 = {}\n",
    "liste_car = ['Galante', '46,2°', 'Trinidad', '20cl', 'cocktail', 'ï']\n",
    "liste_remp = ['Marie Galante', 'Ecosse', 'Trinite et Tobago', 'Martinique', 'France', 'i']\n",
    "# création du dictionnaire avec une compréhension de dictionnaire\n",
    "dico2 = {k: v for k, v in zip(liste_car, liste_remp)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# il faut que regex=True \n",
    "df1.replace({'producteurs': dico}, regex=True,inplace=True)\n",
    "df1.replace({'origines': dico2}, regex=True,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('test_json_final.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "missing-geology",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-clark",
   "metadata": {},
   "source": [
    "- nettoyage new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'rhumfullinfo_wikirum.csv'\n",
    "new_data = pd.read_csv(csv_file)\n",
    "\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()\n",
    "index_with_nan = new_data.index[new_data.isnull().any(axis=1)]\n",
    "new_data.drop(index_with_nan,0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns = ['nom', 'producteur', 'origine', 'volume', 'degre']\n",
    "new_data['producteur'] = new_data['producteur'].str.replace('*','', regex=True)\n",
    "new_data['nom'] = new_data['nom'].str.replace('\\'','', regex=True)\n",
    "new_data['producteur'] = new_data['producteur'].str.replace('\\'','', regex=True)\n",
    "new_data['degre'] = new_data['degre'].astype(float)\n",
    "new_data['volume'] = new_data['volume'].astype(int)\n",
    "new_data['volume'] = new_data['volume'] / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('new_data_wiki.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-travel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "advance-discharge",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-horizon",
   "metadata": {},
   "source": [
    "### Insertion des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gothic-phenomenon",
   "metadata": {},
   "source": [
    "- origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-wireless",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prod\n",
    "# liste des origines pour insertions\n",
    "\n",
    "import csv\n",
    "# je crée une liste regroupant ma liste de pays\n",
    "liste = []\n",
    "with open('rum_data_new3.csv', newline='', encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        # gestion des doublons\n",
    "        if row[2] not in liste:\n",
    "            liste.append(row[2])\n",
    "liste = liste[1:]\n",
    "print(liste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connexion à la bdd collection\n",
    "conn = psycopg2.connect(\n",
    "        user = \"postgres\",\n",
    "        password = os.environ.get(\"pg_psw\"),\n",
    "        host = \"localhost\",\n",
    "        port = \"5432\",\n",
    "        database = \"collection4\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for pays in liste:\n",
    "    cur.execute(\"SELECT origine.nom FROM origine WHERE origine.nom = (%s) \", (pays,))\n",
    "    verif = cur.fetchone()\n",
    "    if not verif:\n",
    "        cur.execute(\"INSERT INTO origine (nom) VALUES(%s)\", (pays,))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-determination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "declared-destination",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-attribute",
   "metadata": {},
   "source": [
    "- insertion producteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod\n",
    "# je crée une liste regroupant les pays et les producteurs\n",
    "liste_co = []\n",
    "with open('rum_data_new3.csv', newline='', encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if row[1:3] not in liste_co:\n",
    "            liste_co.append((row[1:3]))\n",
    "liste_co = liste_co[1:]\n",
    "print(liste_co[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod\n",
    "# fonction d'insertion dans la table producteur\n",
    "conn = psycopg2.connect(\n",
    "        user = \"postgres\",\n",
    "        password = os.environ.get(\"pg_psw\"),\n",
    "        host = \"localhost\",\n",
    "        port = \"5432\",\n",
    "        database = \"collection4\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "for producteur, pays in liste_co:\n",
    "    #print(producteur)\n",
    "    #print(pays)\n",
    "    cur.execute(f\"\"\"SELECT origine.code_origine \n",
    "        FROM origine\n",
    "        WHERE origine.nom = '{pays}';\n",
    "        \"\"\")\n",
    "    \n",
    "    origine = cur.fetchone()[0]\n",
    "    #print(origine)\n",
    "    #pays = str(pro[0])\n",
    "    #print(pays)\n",
    "\n",
    "    cur.execute(f\"INSERT INTO producteur (nom, code_origine) VALUES ('{producteur}', {origine})\")\n",
    "    \n",
    "cur.close()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-beads",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-peninsula",
   "metadata": {},
   "source": [
    "- insertion produit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-coalition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion fichier excel\n",
    "excel_file = 'INVENTAIRE_B.xlsx'\n",
    "inventaire = pd.read_excel(excel_file)\n",
    "inventaire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-disposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventaire_produit =  inventaire[['NOM', 'VOLUME', 'DEGRE', 'MARQUE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-phrase",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "liste_inventaire = [list(x) for x in inventaire_produit.to_numpy()]\n",
    "print(liste_inventaire[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "nom = liste_inventaire[0][0]\n",
    "volume = liste_inventaire[0][1]\n",
    "degre = liste_inventaire[0][2]\n",
    "marque = liste_inventaire[0][3]\n",
    "\n",
    "print(nom)\n",
    "print(volume)\n",
    "print(degre)\n",
    "print(marque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "        user = \"postgres\",\n",
    "        password = os.environ.get(\"pg_psw\"),\n",
    "        host = \"localhost\",\n",
    "        port = \"5432\",\n",
    "        database = \"collection4\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "for nom, volume, degre, marque in liste_inventaire:\n",
    "    print(marque)\n",
    "    \n",
    "    cur.execute(f\"\"\"SELECT producteur.code_producteur \n",
    "        FROM producteur\n",
    "        WHERE producteur.nom = '{marque}';\n",
    "        \"\"\")\n",
    "    \n",
    "    code = cur.fetchone()[0]\n",
    "    print(code)\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO produit (nom, volume, degre, code_producteur) VALUES ('{nom}', {volume}, {degre}, {code})\")\n",
    "print(type(cur))   \n",
    "cur.close()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-cooper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insertion fichuer csv\n",
    "# prod\n",
    "# je crée une liste regroupant les pays et les producteurs\n",
    "liste_groupe = []\n",
    "with open('rum_data_new3.csv', newline='', encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        liste_groupe.append((row[0:2]))\n",
    "liste_groupe = liste_groupe[1:]\n",
    "print(liste_groupe[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "        user = \"postgres\",\n",
    "        password = os.environ.get(\"pg_psw\"),\n",
    "        host = \"localhost\",\n",
    "        port = \"5432\",\n",
    "        database = \"collection4\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "for nom, marque in liste_groupe:\n",
    "    #print(producteur)\n",
    "    #print(pays)\n",
    "    cur.execute(f\"\"\"SELECT producteur.code_producteur \n",
    "        FROM producteur\n",
    "        WHERE producteur.nom = '{marque}';\n",
    "        \"\"\")\n",
    "    code = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute(f\"INSERT INTO produit (nom, code_producteur) VALUES ('{nom}', {code})\")\n",
    "print(type(cur))   \n",
    "cur.close()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
